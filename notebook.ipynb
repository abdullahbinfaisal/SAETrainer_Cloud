{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6977d6",
   "metadata": {},
   "source": [
    "Initialize Repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52913866",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown --upgrade\n",
    "!pip install overcomplete\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa049167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"oracle_saes\", exist_ok=True)\n",
    "os.makedirs(\"oracle_selection_models\", exist_ok=True)\n",
    "os.makedirs(\"./domainbed/data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o ./domainbed/data/PACS.zip https://www.kaggle.com/api/v1/datasets/download/ma3ple/pacs-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c245f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip ./domainbed/data/PACS.zip -d ./domainbed/data/\n",
    "!mv -f ./domainbed/data/kfold ./domainbed/data/PACS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29003d8",
   "metadata": {},
   "source": [
    "### Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d087f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "data_dir = r\"C:\\Users\\sproj_ha\\Desktop\\domainbed\\domainbed\\data\"\n",
    "dataset = \"PACS\"\n",
    "algorithms = [\"ERM\", \"IRM\", \"DANN\", \"CORAL\", \"Mixup\", \"MMD\", \"SagNet\"]\n",
    "test_env_combinations = [\"0 1\", \"0 2\", \"0 3\", \"1 0\", \"1 2\", \"1 3\", \"2 3\"]\n",
    "backbones = [\"ResNet50\", \"VIT\", \"DINO\"]\n",
    "output_root = \"./results/PACS_Models\"\n",
    "base_cmd = \"python -m domainbed.scripts.train\"\n",
    "\n",
    "# --- RUN ALL COMMANDS SEQUENTIALLY ---\n",
    "for alg in algorithms:\n",
    "    for test_envs in test_env_combinations:\n",
    "        for backbone in backbones:\n",
    "            hparams = {\n",
    "                \"ResNet50\": \"{\\\"resnet50_augmix\\\": true, \\\"vit\\\": false, \\\"dinov2\\\": false}\",\n",
    "                \"VIT\": \"{\\\"resnet50_augmix\\\": false, \\\"vit\\\": true, \\\"dinov2\\\": false}\",\n",
    "                \"DINO\": \"{\\\"resnet50_augmix\\\": false, \\\"vit\\\": true, \\\"dinov2\\\": true}\"\n",
    "            }[backbone]\n",
    "    \n",
    "            output_dir = f\"{output_root}/{alg}_{backbone}_T{test_envs.replace(' ', '')}\"\n",
    "                        \n",
    "            cmd = (\n",
    "                f'{base_cmd} '\n",
    "                f'--data_dir \"{data_dir}\" '\n",
    "                f'--dataset {dataset} '\n",
    "                f'--algorithm {alg} '\n",
    "                f'--hparams \"{hparams}\" '\n",
    "                f'--test_envs {test_envs} '\n",
    "                f'--output_dir {output_dir} '\n",
    "                f'--save_model_every_checkpoint '\n",
    "                f'--hparams_seed 0 --trial_seed 0 --seed 0'\n",
    "            )\n",
    "\n",
    "            print(f\"\\nüöÄ Running: {cmd}\\n\")\n",
    "            try:\n",
    "                subprocess.run(cmd, shell=True, check=True)\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"‚ùå Command failed: {e}\")\n",
    "            \n",
    "            # --- CLEAR CACHE BETWEEN RUNS ---\n",
    "            try:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    print(\"üßπ Cleared CUDA cache.\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Could not clear CUDA cache: {e}\")\n",
    "            \n",
    "            # Optionally clear OS-level file system cache (Linux only)\n",
    "            if os.name == \"posix\":\n",
    "                os.system(\"sync; echo 3 | sudo tee /proc/sys/vm/drop_caches > /dev/null 2>&1\")\n",
    "                print(\"üßΩ Dropped system caches (Linux).\")\n",
    "\n",
    "print(\"\\n‚úÖ All commands finished running sequentially.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a17a8e",
   "metadata": {},
   "source": [
    "### Run Oracle Selection on Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e55a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# === Helper functions ===\n",
    "\n",
    "def parse_test_envs(folder_name, file_text):\n",
    "    \"\"\"Extract test environment indices from folder name (e.g. '_T12' -> [1, 2])\"\"\"\n",
    "    match = re.search(r\"_T(\\d+)\", folder_name)\n",
    "    if match:\n",
    "        digits = list(match.group(1))\n",
    "        return [int(d) for d in digits]\n",
    "    # Fallback if missing in name: try reading from out.txt header\n",
    "    m2 = re.search(r\"test_envs:\\s*\\[([0-9,\\s]+)\\]\", file_text)\n",
    "    if m2:\n",
    "        return [int(x.strip()) for x in m2.group(1).split(\",\")]\n",
    "    return []\n",
    "\n",
    "def parse_table(file_text):\n",
    "    \"\"\"Parse the main results table from out.txt, robust to DANN spacing and header variants.\"\"\"\n",
    "    # Find all candidate headers\n",
    "    matches = list(re.finditer(r\"^(disc_loss|env0_in_acc)\\s+\", file_text, re.MULTILINE))\n",
    "    if not matches:\n",
    "        raise ValueError(\"Could not locate results table start (env0_in_acc or disc_loss)\")\n",
    "\n",
    "    # Use the last one (main training section)\n",
    "    start_idx = matches[-1].start()\n",
    "    table_text = file_text[start_idx:].strip()\n",
    "    lines = [ln.strip() for ln in table_text.splitlines() if ln.strip()]\n",
    "\n",
    "    # Handle case where the first header is env0_in_acc but next is disc_loss\n",
    "    if lines[0].startswith(\"env0_in_acc\") and len(lines) > 1 and lines[1].startswith(\"disc_loss\"):\n",
    "        lines = lines[1:]\n",
    "\n",
    "    header = re.split(r\"\\s{2,}|\\t+\", lines[0].strip())\n",
    "    data_lines = []\n",
    "    for line in lines[1:]:\n",
    "        if line.startswith(\"Updated state\") or line.startswith(\"Restarting\"):\n",
    "            break\n",
    "        parts = re.split(r\"\\s{2,}|\\t+\", line.strip())\n",
    "        if len(parts) == len(header):\n",
    "            data_lines.append(parts)\n",
    "\n",
    "    if not data_lines:\n",
    "        raise ValueError(\"No valid rows found in results table\")\n",
    "\n",
    "    df = pd.DataFrame(data_lines, columns=header)\n",
    "    # Convert numeric columns\n",
    "    df = df.apply(pd.to_numeric, errors=\"ignore\")\n",
    "    return df\n",
    "\n",
    "def get_best_checkpoint(root_dir):\n",
    "    \"\"\"Traverse experiment folders, read out.txt, and find best model per test env.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for folder in sorted(os.listdir(root_dir)):\n",
    "        folder_path = os.path.join(root_dir, folder)\n",
    "        out_file = os.path.join(folder_path, \"out.txt\")\n",
    "        if not os.path.isfile(out_file):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with open(out_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                text = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to read {folder}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = parse_table(text)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to parse table in {folder}: {e}\")\n",
    "            continue\n",
    "\n",
    "        test_envs = parse_test_envs(folder, text)\n",
    "        if not test_envs:\n",
    "            print(f\"‚ö†Ô∏è No test envs found in {folder}\")\n",
    "            continue\n",
    "\n",
    "        env_accs = [f\"env{t}_out_acc\" for t in test_envs if f\"env{t}_out_acc\" in df.columns]\n",
    "        if not env_accs:\n",
    "            print(f\"‚ö†Ô∏è No env*_out_acc columns found in {folder}\")\n",
    "            continue\n",
    "\n",
    "        # Ensure numeric\n",
    "        df[env_accs] = df[env_accs].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        df[\"weighted_acc\"] = df[env_accs].mean(axis=1)\n",
    "\n",
    "        best_idx = df[\"weighted_acc\"].idxmax()\n",
    "        best_row = df.loc[best_idx]\n",
    "\n",
    "        best_step = str(int(best_row[\"step\"])) if \"step\" in best_row else \"N/A\"\n",
    "\n",
    "        results.append({\n",
    "            \"folder\": folder,\n",
    "            \"folder_path\": folder_path,\n",
    "            \"best_checkpoint\": best_step,\n",
    "            \"weighted_acc\": best_row[\"weighted_acc\"],\n",
    "            **{env_acc: best_row[env_acc] for env_acc in env_accs},\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def copy_best_checkpoints(results, root_dir):\n",
    "    \"\"\"Copy best checkpoint files into Oracle Selection folder.\"\"\"\n",
    "    oracle_dir = os.path.join(root_dir, \"Oracle Selection\")\n",
    "    os.makedirs(oracle_dir, exist_ok=True)\n",
    "\n",
    "    for r in results:\n",
    "        src_folder = r[\"folder_path\"]\n",
    "        dst_folder = os.path.join(oracle_dir, r[\"folder\"])\n",
    "        os.makedirs(dst_folder, exist_ok=True)\n",
    "\n",
    "        step = r[\"best_checkpoint\"]\n",
    "        if step == \"N/A\":\n",
    "            print(f\"‚ö†Ô∏è Skipping {r['folder']} (no valid checkpoint step)\")\n",
    "            continue\n",
    "\n",
    "        checkpoint_name = f\"model_step{step}.pkl\"\n",
    "        src = os.path.join(src_folder, checkpoint_name)\n",
    "        dst = os.path.join(dst_folder, checkpoint_name)\n",
    "\n",
    "        if os.path.exists(src):\n",
    "            shutil.copy2(src, dst)\n",
    "            print(f\"‚úÖ Copied {checkpoint_name} ‚Üí {dst_folder}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No checkpoint found for step {step} in {r['folder']} (expected {checkpoint_name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r\"\"  # üîÅ change this to your experiments root\n",
    "results = get_best_checkpoint(root_dir)\n",
    "\n",
    "print(\"\\n=== Oracle Model Selection Results ===\\n\")\n",
    "for r in results:\n",
    "    print(f\"üìÅ {r['folder']}\")\n",
    "    print(f\"  ‚Üí Best checkpoint: {r['best_checkpoint']}\")\n",
    "    print(f\"  ‚Üí Weighted Acc: {r['weighted_acc']:.4f}\")\n",
    "    for k, v in r.items():\n",
    "        if k.startswith(\"env\") and k.endswith(\"_out_acc\"):\n",
    "            print(f\"     {k}: {v:.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"üì¶ Copying best checkpoints to 'Oracle Selection'...\\n\")\n",
    "copy_best_checkpoints(results, root_dir)\n",
    "print(\"\\n‚úÖ Done! All best checkpoints collected under 'Oracle Selection'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d82432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(root_dir, ignore_errors=True)\n",
    "print(f\"Deleted: {root_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a59be8",
   "metadata": {},
   "source": [
    "### SAE Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9616c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from saetrainer_shell import run\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fb_domainbed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
