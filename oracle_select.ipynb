{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3919fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# === Helper functions ===\n",
    "\n",
    "def parse_test_envs(folder_name, file_text):\n",
    "    \"\"\"Extract test environment indices from folder name (e.g. '_T12' -> [1, 2])\"\"\"\n",
    "    match = re.search(r\"_T(\\d+)\", folder_name)\n",
    "    if match:\n",
    "        digits = list(match.group(1))\n",
    "        return [int(d) for d in digits]\n",
    "    # Fallback if missing in name: try reading from out.txt header\n",
    "    m2 = re.search(r\"test_envs:\\s*\\[([0-9,\\s]+)\\]\", file_text)\n",
    "    if m2:\n",
    "        return [int(x.strip()) for x in m2.group(1).split(\",\")]\n",
    "    return []\n",
    "\n",
    "def parse_table(file_text):\n",
    "    \"\"\"Parse the main results table from out.txt, robust to DANN spacing and header variants.\"\"\"\n",
    "    # Find all candidate headers\n",
    "    matches = list(re.finditer(r\"^(disc_loss|env0_in_acc)\\s+\", file_text, re.MULTILINE))\n",
    "    if not matches:\n",
    "        raise ValueError(\"Could not locate results table start (env0_in_acc or disc_loss)\")\n",
    "\n",
    "    # Use the last one (main training section)\n",
    "    start_idx = matches[-1].start()\n",
    "    table_text = file_text[start_idx:].strip()\n",
    "    lines = [ln.strip() for ln in table_text.splitlines() if ln.strip()]\n",
    "\n",
    "    # Handle case where the first header is env0_in_acc but next is disc_loss\n",
    "    if lines[0].startswith(\"env0_in_acc\") and len(lines) > 1 and lines[1].startswith(\"disc_loss\"):\n",
    "        lines = lines[1:]\n",
    "\n",
    "    header = re.split(r\"\\s{2,}|\\t+\", lines[0].strip())\n",
    "    data_lines = []\n",
    "    for line in lines[1:]:\n",
    "        if line.startswith(\"Updated state\") or line.startswith(\"Restarting\"):\n",
    "            break\n",
    "        parts = re.split(r\"\\s{2,}|\\t+\", line.strip())\n",
    "        if len(parts) == len(header):\n",
    "            data_lines.append(parts)\n",
    "\n",
    "    if not data_lines:\n",
    "        raise ValueError(\"No valid rows found in results table\")\n",
    "\n",
    "    df = pd.DataFrame(data_lines, columns=header)\n",
    "    # Convert numeric columns\n",
    "    df = df.apply(pd.to_numeric, errors=\"ignore\")\n",
    "    return df\n",
    "\n",
    "def get_best_checkpoint(root_dir):\n",
    "    \"\"\"Traverse experiment folders, read out.txt, and find best model per test env.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for folder in sorted(os.listdir(root_dir)):\n",
    "        folder_path = os.path.join(root_dir, folder)\n",
    "        out_file = os.path.join(folder_path, \"out.txt\")\n",
    "        if not os.path.isfile(out_file):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with open(out_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                text = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to read {folder}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df = parse_table(text)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to parse table in {folder}: {e}\")\n",
    "            continue\n",
    "\n",
    "        test_envs = parse_test_envs(folder, text)\n",
    "        if not test_envs:\n",
    "            print(f\"‚ö†Ô∏è No test envs found in {folder}\")\n",
    "            continue\n",
    "\n",
    "        env_accs = [f\"env{t}_out_acc\" for t in test_envs if f\"env{t}_out_acc\" in df.columns]\n",
    "        if not env_accs:\n",
    "            print(f\"‚ö†Ô∏è No env*_out_acc columns found in {folder}\")\n",
    "            continue\n",
    "\n",
    "        # Ensure numeric\n",
    "        df[env_accs] = df[env_accs].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        df[\"weighted_acc\"] = df[env_accs].mean(axis=1)\n",
    "\n",
    "        best_idx = df[\"weighted_acc\"].idxmax()\n",
    "        best_row = df.loc[best_idx]\n",
    "\n",
    "        best_step = str(int(best_row[\"step\"])) if \"step\" in best_row else \"N/A\"\n",
    "\n",
    "        results.append({\n",
    "            \"folder\": folder,\n",
    "            \"folder_path\": folder_path,\n",
    "            \"best_checkpoint\": best_step,\n",
    "            \"weighted_acc\": best_row[\"weighted_acc\"],\n",
    "            **{env_acc: best_row[env_acc] for env_acc in env_accs},\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def copy_best_checkpoints(results, root_dir):\n",
    "    \"\"\"Copy best checkpoint files into Oracle Selection folder.\"\"\"\n",
    "    oracle_dir = os.path.join(root_dir, \"Oracle Selection\")\n",
    "    os.makedirs(oracle_dir, exist_ok=True)\n",
    "\n",
    "    for r in results:\n",
    "        src_folder = r[\"folder_path\"]\n",
    "        dst_folder = os.path.join(oracle_dir, r[\"folder\"])\n",
    "        os.makedirs(dst_folder, exist_ok=True)\n",
    "\n",
    "        step = r[\"best_checkpoint\"]\n",
    "        if step == \"N/A\":\n",
    "            print(f\"‚ö†Ô∏è Skipping {r['folder']} (no valid checkpoint step)\")\n",
    "            continue\n",
    "\n",
    "        checkpoint_name = f\"model_step{step}.pkl\"\n",
    "        src = os.path.join(src_folder, checkpoint_name)\n",
    "        dst = os.path.join(dst_folder, checkpoint_name)\n",
    "\n",
    "        if os.path.exists(src):\n",
    "            shutil.copy2(src, dst)\n",
    "            print(f\"‚úÖ Copied {checkpoint_name} ‚Üí {dst_folder}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No checkpoint found for step {step} in {r['folder']} (expected {checkpoint_name})\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = r\"D:\\SPROJ_ABLATE_PACS\"  # üîÅ change this to your experiments root\n",
    "    results = get_best_checkpoint(root_dir)\n",
    "\n",
    "    print(\"\\n=== Oracle Model Selection Results ===\\n\")\n",
    "    for r in results:\n",
    "        print(f\"üìÅ {r['folder']}\")\n",
    "        print(f\"  ‚Üí Best checkpoint: {r['best_checkpoint']}\")\n",
    "        print(f\"  ‚Üí Weighted Acc: {r['weighted_acc']:.4f}\")\n",
    "        for k, v in r.items():\n",
    "            if k.startswith(\"env\") and k.endswith(\"_out_acc\"):\n",
    "                print(f\"     {k}: {v:.4f}\")\n",
    "        print()\n",
    "\n",
    "    print(\"üì¶ Copying best checkpoints to 'Oracle Selection'...\\n\")\n",
    "    copy_best_checkpoints(results, root_dir)\n",
    "    print(\"\\n‚úÖ Done! All best checkpoints collected under 'Oracle Selection'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8280ae57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
